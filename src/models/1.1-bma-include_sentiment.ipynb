{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few starting parameters... (*none of these have been used yet*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The days from which we calculate drift (mu) and diffusion (sigma)\n",
    "startday = 800   # '0' corresponds to 2015-02-01, it counts up from there\n",
    "endday = 1108\n",
    "\n",
    "N = 100    # number of days to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in & Formatting Price Data\n",
    "The .csv read from contains the price of [bitcoin](https://bitcoin.org/en/) from 2015-02-01 to 2018-02-13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    226.3959\n",
      "1    237.5409\n",
      "Name: price, dtype: float64\n",
      "1107    8891.2125\n",
      "1108    8516.2438\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "prices_raw = pd.read_csv('data/price_data.csv', infer_datetime_format=True)\n",
    "p = prices_raw['price']\n",
    "print(p.head(2))\n",
    "print(p.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in & Formatting Quantified Sentiment\n",
    "The .csv we read from here contains daily sentiment scores from 2015-02-01 to 2018-02-13 for the title of every post in the [Bitcoin subreddit](https://www.reddit.com/r/Bitcoin/), an online Bitcoin community.\n",
    "\n",
    "There seems to be *a lot* of noise in the form of 0's (neutral sentiment). **How can this effectively be handled?**\n",
    "\n",
    "For now, I will take the daily average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.068356\n",
      "1    0.068356\n",
      "dtype: float64\n",
      "1107    0.046143\n",
      "1108    0.004784\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sentiment_raw = pd.read_csv('data/reddit_sentiment_data.csv', infer_datetime_format=True)\n",
    "s = sentiment_raw.mean(axis=1)\n",
    "print(s.head(2))\n",
    "print(s.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating dS as predicted by [Geometric Brownian Motion](https://en.wikipedia.org/wiki/Geometric_Brownian_motion), where S = Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def GBM_step(mu, S, N, sigma, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
